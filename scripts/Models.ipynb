{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:48: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.feature_selection import RFECV, SelectFromModel\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, Normalizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "import xgboost as XGB\n",
    "import lightgbm\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.read_pickle('../output/preprocessed_train.pkl')\n",
    "test = pd.read_pickle('../output/preprocessed_test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keep a hold out test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891 713 178\n"
     ]
    }
   ],
   "source": [
    "validation = train_raw.sample(frac=0.2)\n",
    "\n",
    "train = train_raw.loc[~train_raw.index.isin(validation.index), :]\n",
    "\n",
    "print(train_raw.shape[0], train.shape[0], validation.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 713 entries, 1 to 890\n",
      "Data columns (total 18 columns):\n",
      "PassengerId    713 non-null int64\n",
      "Survived       713 non-null int64\n",
      "Pclass         713 non-null int64\n",
      "Name           713 non-null object\n",
      "Sex            713 non-null object\n",
      "Age            713 non-null float64\n",
      "SibSp          713 non-null int64\n",
      "Parch          713 non-null int64\n",
      "Ticket         713 non-null object\n",
      "Fare           713 non-null float64\n",
      "Cabin          713 non-null object\n",
      "Embarked       713 non-null object\n",
      "cabin_cat      713 non-null object\n",
      "family_size    713 non-null int64\n",
      "family_cat     713 non-null object\n",
      "Initial        713 non-null object\n",
      "fare_range     713 non-null category\n",
      "fare_cat       713 non-null category\n",
      "dtypes: category(2), float64(2), int64(6), object(8)\n",
      "memory usage: 96.3+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 17 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            418 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           418 non-null float64\n",
      "Cabin          418 non-null object\n",
      "Embarked       418 non-null object\n",
      "cabin_cat      418 non-null object\n",
      "family_size    418 non-null int64\n",
      "family_cat     418 non-null object\n",
      "Initial        418 non-null object\n",
      "fare_range     418 non-null category\n",
      "fare_cat       418 non-null category\n",
      "dtypes: category(2), float64(2), int64(5), object(8)\n",
      "memory usage: 50.0+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convntional Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering and Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = ['Pclass', 'Sex', 'Embarked', 'cabin_cat', 'family_cat', 'Initial', 'fare_cat']\n",
    "num_cols = ['Age', 'Fare', 'family_size']\n",
    "\n",
    "onehot_transformer = ColumnTransformer(transformers=[\n",
    "                                                      ('num', MinMaxScaler(), num_cols),\n",
    "                                                      ('cat', OneHotEncoder(sparse=True), cat_cols)\n",
    "                                                      ],\n",
    "                                        remainder='drop')\n",
    "ordinal_transformer = ColumnTransformer(transformers=[\n",
    "                                                      ('num', MinMaxScaler(), num_cols),\n",
    "                                                      ('cat', OrdinalEncoder(), cat_cols)\n",
    "                                                      ],\n",
    "                                        remainder='drop')\n",
    "rfe = RFECV(ExtraTreeClassifier(), cv=3, verbose=True, n_jobs=1)\n",
    "coef = SelectFromModel(LogisticRegression())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = ordinal_transformer.fit_transform(train)\n",
    "y_train = train.Survived.values\n",
    "x_val = ordinal_transformer.fit_transform(validation)\n",
    "y_val = validation.Survived.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = {'objective': 'binary'}\n",
    "# lgbm = lightgbm.sklearn.LGBMClassifier()\n",
    "# lgbm.fit(x_train, y_train)\n",
    "# lgbm.score(x_val, y_val)\n",
    "# x_test = ordinal_transformer.fit_transform(test)\n",
    "# test['Survived'] = lgbm.predict(x_test)\n",
    "# test[['PassengerId', 'Survived']].to_csv('../output/titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    5.4s\n",
      "[Parallel(n_jobs=2)]: Done 206 tasks      | elapsed:   20.2s\n",
      "[Parallel(n_jobs=2)]: Done 324 out of 324 | elapsed:   29.9s finished\n",
      "/Users/zhuguanchen/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transform', 'passthrough'),\n",
       "                                       ('feature', 'passthrough'),\n",
       "                                       ('clf',\n",
       "                                        SVC(C=1.0, cache_size=200,\n",
       "                                            class_weight=None, coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001...\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('num',\n",
       "                                                                         MinMaxScaler(copy=True,\n",
       "                                                                                      feature_range=(0,\n",
       "                                                                                                     1)),\n",
       "                                                                         ['Age',\n",
       "                                                                          'Fare',\n",
       "                                                                          'family_size']),\n",
       "                                                                        ('cat',\n",
       "                                                                         OrdinalEncoder(categories='auto',\n",
       "                                                                                        dtype=<class 'numpy.float64'>),\n",
       "                                                                         ['Pclass',\n",
       "                                                                          'Sex',\n",
       "                                                                          'Embarked',\n",
       "                                                                          'cabin_cat',\n",
       "                                                                          'family_cat',\n",
       "                                                                          'Initial',\n",
       "                                                                          'fare_cat'])],\n",
       "                                                          verbose=False)]}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "             scoring=None, verbose=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline = Pipeline(steps=[('transform', 'passthrough'), ('feature', 'passthrough'), ('clf', SVC())])\n",
    "params = [\n",
    "#          {'transform':[onehot_transformer],\n",
    "#           'feature': [rfe, coef],\n",
    "#           'clf__C': [10],\n",
    "#           'clf__gamma': ['scale'],\n",
    "#           'clf__kernel': ['sigmoid', 'rbf']},\n",
    "          {'transform': [ordinal_transformer],\n",
    "           'feature': [rfe, coef],\n",
    "           'clf': [XGB.XGBClassifier()],\n",
    "           'clf__booster': ['dart', 'gblinear'],\n",
    "           'clf__learning_rate': [0.03, 0.1, 1],\n",
    "#            'clf__colsample_bytree': [0.3, 0.7],\n",
    "           'clf__max_depth': [2, 3, 5],\n",
    "#            'clf__subsample': [0.4, 0.6],\n",
    "           'clf__max_delta_step': [0, 1, 5]}]\n",
    "#          {'transform':[onehot_transformer, ordinal_transformer],\n",
    "#           'feature': [rfe, coef],\n",
    "#           'clf': [GradientBoostingClassifier(), RandomForestClassifier()],\n",
    "#           'clf__max_depth': [None, 2, 6, 10],\n",
    "#           'clf__criterion': ['gini', 'entropy'],\n",
    "#           'clf__min_samples_split': [2, 0.1, 0.2],\n",
    "#           'clf__min_samples_leaf': [1, 10, 0.1]}]\n",
    "grid_cv = GridSearchCV(pipeline, param_grid=params, cv=3, refit=True, return_train_score=True, verbose=True, n_jobs=2)\n",
    "grid_cv.fit(train.drop('Survived', axis=1), train.Survived.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf': XGBClassifier(base_score=0.5, booster='dart', colsample_bylevel=1,\n",
       "               colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "               learning_rate=0.03, max_delta_step=0, max_depth=2,\n",
       "               min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "               nthread=None, objective='binary:logistic', random_state=0,\n",
       "               reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "               silent=None, subsample=1, verbosity=1),\n",
       " 'clf__booster': 'dart',\n",
       " 'clf__learning_rate': 0.03,\n",
       " 'clf__max_delta_step': 0,\n",
       " 'clf__max_depth': 2,\n",
       " 'feature': SelectFromModel(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                              dual=False, fit_intercept=True,\n",
       "                                              intercept_scaling=1, l1_ratio=None,\n",
       "                                              max_iter=100, multi_class='warn',\n",
       "                                              n_jobs=None, penalty='l2',\n",
       "                                              random_state=None, solver='warn',\n",
       "                                              tol=0.0001, verbose=0,\n",
       "                                              warm_start=False),\n",
       "                 max_features=None, norm_order=1, prefit=False, threshold=None),\n",
       " 'transform': ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "                   transformer_weights=None,\n",
       "                   transformers=[('num',\n",
       "                                  MinMaxScaler(copy=True, feature_range=(0, 1)),\n",
       "                                  ['Age', 'Fare', 'family_size']),\n",
       "                                 ('cat',\n",
       "                                  OrdinalEncoder(categories='auto',\n",
       "                                                 dtype=<class 'numpy.float64'>),\n",
       "                                  ['Pclass', 'Sex', 'Embarked', 'cabin_cat',\n",
       "                                   'family_cat', 'Initial', 'fare_cat'])],\n",
       "                   verbose=False)}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__booster</th>\n",
       "      <th>param_clf__learning_rate</th>\n",
       "      <th>param_clf__max_delta_step</th>\n",
       "      <th>param_clf__max_depth</th>\n",
       "      <th>param_feature</th>\n",
       "      <th>...</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.262289</td>\n",
       "      <td>0.078859</td>\n",
       "      <td>0.010239</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.819328</td>\n",
       "      <td>0.797468</td>\n",
       "      <td>0.817672</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>33</td>\n",
       "      <td>0.850526</td>\n",
       "      <td>0.835789</td>\n",
       "      <td>0.813025</td>\n",
       "      <td>0.833114</td>\n",
       "      <td>0.015426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.105795</td>\n",
       "      <td>0.019028</td>\n",
       "      <td>0.012084</td>\n",
       "      <td>0.003389</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectFromModel(estimator=LogisticRegression(C...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.840112</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.837895</td>\n",
       "      <td>0.842437</td>\n",
       "      <td>0.840111</td>\n",
       "      <td>0.001856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.364722</td>\n",
       "      <td>0.074895</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815126</td>\n",
       "      <td>0.839662</td>\n",
       "      <td>0.830295</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>14</td>\n",
       "      <td>0.869474</td>\n",
       "      <td>0.865263</td>\n",
       "      <td>0.850840</td>\n",
       "      <td>0.861859</td>\n",
       "      <td>0.007979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.123749</td>\n",
       "      <td>0.007642</td>\n",
       "      <td>0.014017</td>\n",
       "      <td>0.001154</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectFromModel(estimator=LogisticRegression(C...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.843882</td>\n",
       "      <td>0.840112</td>\n",
       "      <td>0.008985</td>\n",
       "      <td>1</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.842437</td>\n",
       "      <td>0.841514</td>\n",
       "      <td>0.001079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.405107</td>\n",
       "      <td>0.091628</td>\n",
       "      <td>0.010538</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>dart</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.827489</td>\n",
       "      <td>0.015429</td>\n",
       "      <td>17</td>\n",
       "      <td>0.907368</td>\n",
       "      <td>0.890526</td>\n",
       "      <td>0.899160</td>\n",
       "      <td>0.899018</td>\n",
       "      <td>0.006876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>0.058923</td>\n",
       "      <td>0.017342</td>\n",
       "      <td>0.014170</td>\n",
       "      <td>0.006144</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>SelectFromModel(estimator=LogisticRegression(C...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>80</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.161414</td>\n",
       "      <td>0.018194</td>\n",
       "      <td>0.014159</td>\n",
       "      <td>0.004197</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.628331</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>69</td>\n",
       "      <td>0.625263</td>\n",
       "      <td>0.646316</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.629742</td>\n",
       "      <td>0.012125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.059702</td>\n",
       "      <td>0.020582</td>\n",
       "      <td>0.014083</td>\n",
       "      <td>0.006109</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>SelectFromModel(estimator=LogisticRegression(C...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>80</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.121450</td>\n",
       "      <td>0.003288</td>\n",
       "      <td>0.010102</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.628692</td>\n",
       "      <td>0.642356</td>\n",
       "      <td>0.027494</td>\n",
       "      <td>55</td>\n",
       "      <td>0.680000</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.621849</td>\n",
       "      <td>0.639564</td>\n",
       "      <td>0.028666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.045342</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.012410</td>\n",
       "      <td>0.001034</td>\n",
       "      <td>XGBClassifier(base_score=0.5, booster='dart', ...</td>\n",
       "      <td>gblinear</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>SelectFromModel(estimator=LogisticRegression(C...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.616034</td>\n",
       "      <td>0.617111</td>\n",
       "      <td>0.000760</td>\n",
       "      <td>80</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.616842</td>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.617110</td>\n",
       "      <td>0.000379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0         0.262289      0.078859         0.010239        0.001296   \n",
       "1         0.105795      0.019028         0.012084        0.003389   \n",
       "2         0.364722      0.074895         0.012093        0.001845   \n",
       "3         0.123749      0.007642         0.014017        0.001154   \n",
       "4         0.405107      0.091628         0.010538        0.002196   \n",
       "..             ...           ...              ...             ...   \n",
       "103       0.058923      0.017342         0.014170        0.006144   \n",
       "104       0.161414      0.018194         0.014159        0.004197   \n",
       "105       0.059702      0.020582         0.014083        0.006109   \n",
       "106       0.121450      0.003288         0.010102        0.001017   \n",
       "107       0.045342      0.006650         0.012410        0.001034   \n",
       "\n",
       "                                             param_clf param_clf__booster  \\\n",
       "0    XGBClassifier(base_score=0.5, booster='dart', ...               dart   \n",
       "1    XGBClassifier(base_score=0.5, booster='dart', ...               dart   \n",
       "2    XGBClassifier(base_score=0.5, booster='dart', ...               dart   \n",
       "3    XGBClassifier(base_score=0.5, booster='dart', ...               dart   \n",
       "4    XGBClassifier(base_score=0.5, booster='dart', ...               dart   \n",
       "..                                                 ...                ...   \n",
       "103  XGBClassifier(base_score=0.5, booster='dart', ...           gblinear   \n",
       "104  XGBClassifier(base_score=0.5, booster='dart', ...           gblinear   \n",
       "105  XGBClassifier(base_score=0.5, booster='dart', ...           gblinear   \n",
       "106  XGBClassifier(base_score=0.5, booster='dart', ...           gblinear   \n",
       "107  XGBClassifier(base_score=0.5, booster='dart', ...           gblinear   \n",
       "\n",
       "    param_clf__learning_rate param_clf__max_delta_step param_clf__max_depth  \\\n",
       "0                       0.03                         0                    2   \n",
       "1                       0.03                         0                    2   \n",
       "2                       0.03                         0                    3   \n",
       "3                       0.03                         0                    3   \n",
       "4                       0.03                         0                    5   \n",
       "..                       ...                       ...                  ...   \n",
       "103                        1                         5                    2   \n",
       "104                        1                         5                    3   \n",
       "105                        1                         5                    3   \n",
       "106                        1                         5                    5   \n",
       "107                        1                         5                    5   \n",
       "\n",
       "                                         param_feature  ... split1_test_score  \\\n",
       "0    RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...  ...          0.819328   \n",
       "1    SelectFromModel(estimator=LogisticRegression(C...  ...          0.848739   \n",
       "2    RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...  ...          0.815126   \n",
       "3    SelectFromModel(estimator=LogisticRegression(C...  ...          0.848739   \n",
       "4    RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...  ...          0.823529   \n",
       "..                                                 ...  ...               ...   \n",
       "103  SelectFromModel(estimator=LogisticRegression(C...  ...          0.617647   \n",
       "104  RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...  ...          0.647059   \n",
       "105  SelectFromModel(estimator=LogisticRegression(C...  ...          0.617647   \n",
       "106  RFECV(cv=3,\\n      estimator=ExtraTreeClassifi...  ...          0.617647   \n",
       "107  SelectFromModel(estimator=LogisticRegression(C...  ...          0.617647   \n",
       "\n",
       "    split2_test_score  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0            0.797468         0.817672        0.015823               33   \n",
       "1            0.843882         0.840112        0.008985                1   \n",
       "2            0.839662         0.830295        0.010833               14   \n",
       "3            0.843882         0.840112        0.008985                1   \n",
       "4            0.848101         0.827489        0.015429               17   \n",
       "..                ...              ...             ...              ...   \n",
       "103          0.616034         0.617111        0.000760               80   \n",
       "104          0.616034         0.628331        0.013467               69   \n",
       "105          0.616034         0.617111        0.000760               80   \n",
       "106          0.628692         0.642356        0.027494               55   \n",
       "107          0.616034         0.617111        0.000760               80   \n",
       "\n",
       "     split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0              0.850526            0.835789            0.813025   \n",
       "1              0.840000            0.837895            0.842437   \n",
       "2              0.869474            0.865263            0.850840   \n",
       "3              0.840000            0.842105            0.842437   \n",
       "4              0.907368            0.890526            0.899160   \n",
       "..                  ...                 ...                 ...   \n",
       "103            0.616842            0.616842            0.617647   \n",
       "104            0.625263            0.646316            0.617647   \n",
       "105            0.616842            0.616842            0.617647   \n",
       "106            0.680000            0.616842            0.621849   \n",
       "107            0.616842            0.616842            0.617647   \n",
       "\n",
       "     mean_train_score  std_train_score  \n",
       "0            0.833114         0.015426  \n",
       "1            0.840111         0.001856  \n",
       "2            0.861859         0.007979  \n",
       "3            0.841514         0.001079  \n",
       "4            0.899018         0.006876  \n",
       "..                ...              ...  \n",
       "103          0.617110         0.000379  \n",
       "104          0.629742         0.012125  \n",
       "105          0.617110         0.000379  \n",
       "106          0.639564         0.028666  \n",
       "107          0.617110         0.000379  \n",
       "\n",
       "[108 rows x 23 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_cv.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8401122019635343"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.797752808988764"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_cv.score(validation.drop('Survived', axis=1), validation.Survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = onehot_transformer.fit_transform(train.drop('Survived', axis=1))\n",
    "y = train.Survived.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(534, 24)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_model = tf.keras.Sequential(\n",
    "    [tf.keras.layers.Dense(50, activation='relu', input_shape=(24,)),\n",
    "#      tf.keras.layers.Dropout(0.2),\n",
    "#      tf.keras.layers.Dense(30, activation='relu'),\n",
    "#      tf.keras.layers.Dropout(0.2),\n",
    "     tf.keras.layers.Dense(30, activation='relu'),\n",
    "     tf.keras.layers.Dropout(0.5),\n",
    "     tf.keras.layers.Dense(10, activation='relu'),\n",
    "     tf.keras.layers.Dropout(0.5),\n",
    "     tf.keras.layers.Dense(5, activation='relu'),\n",
    "     tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "dl_model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 534 samples, validate on 179 samples\n",
      "Epoch 1/50\n",
      "534/534 [==============================] - 1s 2ms/sample - loss: 0.6597 - accuracy: 0.5861 - val_loss: 0.6408 - val_accuracy: 0.6648\n",
      "Epoch 2/50\n",
      "534/534 [==============================] - 0s 227us/sample - loss: 0.6403 - accuracy: 0.6161 - val_loss: 0.6161 - val_accuracy: 0.6648\n",
      "Epoch 3/50\n",
      "534/534 [==============================] - 0s 181us/sample - loss: 0.6264 - accuracy: 0.6348 - val_loss: 0.6020 - val_accuracy: 0.6872\n",
      "Epoch 4/50\n",
      "534/534 [==============================] - 0s 197us/sample - loss: 0.6076 - accuracy: 0.6648 - val_loss: 0.5602 - val_accuracy: 0.6816\n",
      "Epoch 5/50\n",
      "534/534 [==============================] - 0s 181us/sample - loss: 0.6136 - accuracy: 0.6554 - val_loss: 0.5492 - val_accuracy: 0.6816\n",
      "Epoch 6/50\n",
      "534/534 [==============================] - 0s 193us/sample - loss: 0.5914 - accuracy: 0.6704 - val_loss: 0.5486 - val_accuracy: 0.6927\n",
      "Epoch 7/50\n",
      "534/534 [==============================] - 0s 183us/sample - loss: 0.5735 - accuracy: 0.6704 - val_loss: 0.5385 - val_accuracy: 0.6816\n",
      "Epoch 8/50\n",
      "534/534 [==============================] - 0s 202us/sample - loss: 0.5857 - accuracy: 0.6891 - val_loss: 0.5266 - val_accuracy: 0.7207\n",
      "Epoch 9/50\n",
      "534/534 [==============================] - 0s 187us/sample - loss: 0.5715 - accuracy: 0.6966 - val_loss: 0.5272 - val_accuracy: 0.7709\n",
      "Epoch 10/50\n",
      "534/534 [==============================] - 0s 204us/sample - loss: 0.5637 - accuracy: 0.7154 - val_loss: 0.5132 - val_accuracy: 0.7821\n",
      "Epoch 11/50\n",
      "534/534 [==============================] - 0s 176us/sample - loss: 0.5372 - accuracy: 0.7566 - val_loss: 0.4979 - val_accuracy: 0.7877\n",
      "Epoch 12/50\n",
      "534/534 [==============================] - 0s 221us/sample - loss: 0.5242 - accuracy: 0.7566 - val_loss: 0.4821 - val_accuracy: 0.7821\n",
      "Epoch 13/50\n",
      "534/534 [==============================] - 0s 181us/sample - loss: 0.5567 - accuracy: 0.7285 - val_loss: 0.4751 - val_accuracy: 0.8156\n",
      "Epoch 14/50\n",
      "534/534 [==============================] - 0s 204us/sample - loss: 0.5484 - accuracy: 0.7453 - val_loss: 0.4709 - val_accuracy: 0.8045\n",
      "Epoch 15/50\n",
      "534/534 [==============================] - 0s 197us/sample - loss: 0.4816 - accuracy: 0.8034 - val_loss: 0.4628 - val_accuracy: 0.8212\n",
      "Epoch 16/50\n",
      "534/534 [==============================] - 0s 185us/sample - loss: 0.5158 - accuracy: 0.7790 - val_loss: 0.4580 - val_accuracy: 0.7877\n",
      "Epoch 17/50\n",
      "534/534 [==============================] - 0s 197us/sample - loss: 0.5121 - accuracy: 0.7715 - val_loss: 0.4620 - val_accuracy: 0.8045\n",
      "Epoch 18/50\n",
      "534/534 [==============================] - 0s 185us/sample - loss: 0.5051 - accuracy: 0.7734 - val_loss: 0.4614 - val_accuracy: 0.8045\n",
      "Epoch 19/50\n",
      "534/534 [==============================] - 0s 198us/sample - loss: 0.4920 - accuracy: 0.7884 - val_loss: 0.4582 - val_accuracy: 0.7877\n",
      "Epoch 20/50\n",
      "534/534 [==============================] - 0s 197us/sample - loss: 0.5066 - accuracy: 0.7697 - val_loss: 0.4576 - val_accuracy: 0.7933\n",
      "Epoch 21/50\n",
      "534/534 [==============================] - 0s 256us/sample - loss: 0.4795 - accuracy: 0.8146 - val_loss: 0.4469 - val_accuracy: 0.8101\n",
      "Epoch 22/50\n",
      "534/534 [==============================] - 0s 206us/sample - loss: 0.4891 - accuracy: 0.7959 - val_loss: 0.4428 - val_accuracy: 0.8045\n",
      "Epoch 23/50\n",
      "534/534 [==============================] - 0s 180us/sample - loss: 0.4680 - accuracy: 0.7865 - val_loss: 0.4338 - val_accuracy: 0.8156\n",
      "Epoch 24/50\n",
      "534/534 [==============================] - 0s 180us/sample - loss: 0.4437 - accuracy: 0.8052 - val_loss: 0.4231 - val_accuracy: 0.8101\n",
      "Epoch 25/50\n",
      "534/534 [==============================] - 0s 182us/sample - loss: 0.4423 - accuracy: 0.8165 - val_loss: 0.4177 - val_accuracy: 0.8101\n",
      "Epoch 26/50\n",
      "534/534 [==============================] - 0s 202us/sample - loss: 0.4626 - accuracy: 0.7921 - val_loss: 0.4184 - val_accuracy: 0.8101\n",
      "Epoch 27/50\n",
      "534/534 [==============================] - 0s 183us/sample - loss: 0.4709 - accuracy: 0.7903 - val_loss: 0.4206 - val_accuracy: 0.8045\n",
      "Epoch 28/50\n",
      "534/534 [==============================] - 0s 220us/sample - loss: 0.4945 - accuracy: 0.8015 - val_loss: 0.4259 - val_accuracy: 0.8045\n",
      "Epoch 29/50\n",
      "534/534 [==============================] - 0s 249us/sample - loss: 0.4459 - accuracy: 0.7996 - val_loss: 0.4239 - val_accuracy: 0.8101\n",
      "Epoch 30/50\n",
      "534/534 [==============================] - 0s 204us/sample - loss: 0.4352 - accuracy: 0.7884 - val_loss: 0.4133 - val_accuracy: 0.8101\n",
      "Epoch 31/50\n",
      "534/534 [==============================] - 0s 189us/sample - loss: 0.4551 - accuracy: 0.7978 - val_loss: 0.4113 - val_accuracy: 0.8101\n",
      "Epoch 32/50\n",
      "534/534 [==============================] - 0s 184us/sample - loss: 0.4661 - accuracy: 0.7809 - val_loss: 0.4142 - val_accuracy: 0.8212\n",
      "Epoch 33/50\n",
      "534/534 [==============================] - 0s 193us/sample - loss: 0.4478 - accuracy: 0.8221 - val_loss: 0.4176 - val_accuracy: 0.8380\n",
      "Epoch 34/50\n",
      "534/534 [==============================] - 0s 258us/sample - loss: 0.4416 - accuracy: 0.8184 - val_loss: 0.4099 - val_accuracy: 0.8045\n",
      "Epoch 35/50\n",
      "534/534 [==============================] - 0s 208us/sample - loss: 0.4311 - accuracy: 0.8240 - val_loss: 0.4063 - val_accuracy: 0.8212\n",
      "Epoch 36/50\n",
      "534/534 [==============================] - 0s 197us/sample - loss: 0.4223 - accuracy: 0.8052 - val_loss: 0.4055 - val_accuracy: 0.8156\n",
      "Epoch 37/50\n",
      "534/534 [==============================] - 0s 181us/sample - loss: 0.4347 - accuracy: 0.7978 - val_loss: 0.4039 - val_accuracy: 0.8156\n",
      "Epoch 38/50\n",
      "534/534 [==============================] - 0s 179us/sample - loss: 0.4484 - accuracy: 0.8240 - val_loss: 0.4048 - val_accuracy: 0.8101\n",
      "Epoch 39/50\n",
      "534/534 [==============================] - 0s 206us/sample - loss: 0.4454 - accuracy: 0.8165 - val_loss: 0.4062 - val_accuracy: 0.8324\n",
      "Epoch 40/50\n",
      "534/534 [==============================] - 0s 183us/sample - loss: 0.4509 - accuracy: 0.8184 - val_loss: 0.4156 - val_accuracy: 0.8268\n",
      "Epoch 41/50\n",
      "534/534 [==============================] - 0s 206us/sample - loss: 0.4304 - accuracy: 0.8109 - val_loss: 0.4107 - val_accuracy: 0.8212\n",
      "Epoch 42/50\n",
      "534/534 [==============================] - 0s 249us/sample - loss: 0.4380 - accuracy: 0.7996 - val_loss: 0.4073 - val_accuracy: 0.8268\n",
      "Epoch 43/50\n",
      "534/534 [==============================] - 0s 188us/sample - loss: 0.4205 - accuracy: 0.8034 - val_loss: 0.4040 - val_accuracy: 0.8268\n",
      "Epoch 44/50\n",
      "534/534 [==============================] - 0s 180us/sample - loss: 0.4309 - accuracy: 0.8071 - val_loss: 0.3988 - val_accuracy: 0.8268\n",
      "Epoch 45/50\n",
      "534/534 [==============================] - 0s 201us/sample - loss: 0.4436 - accuracy: 0.8071 - val_loss: 0.3977 - val_accuracy: 0.8436\n",
      "Epoch 46/50\n",
      "534/534 [==============================] - 0s 195us/sample - loss: 0.4205 - accuracy: 0.8165 - val_loss: 0.3999 - val_accuracy: 0.8324\n",
      "Epoch 47/50\n",
      "534/534 [==============================] - 0s 206us/sample - loss: 0.4338 - accuracy: 0.8034 - val_loss: 0.3991 - val_accuracy: 0.8380\n",
      "Epoch 48/50\n",
      "534/534 [==============================] - 0s 178us/sample - loss: 0.3986 - accuracy: 0.8258 - val_loss: 0.3995 - val_accuracy: 0.8436\n",
      "Epoch 49/50\n",
      "534/534 [==============================] - 0s 204us/sample - loss: 0.4169 - accuracy: 0.8277 - val_loss: 0.4034 - val_accuracy: 0.8436\n",
      "Epoch 50/50\n",
      "534/534 [==============================] - 0s 197us/sample - loss: 0.4222 - accuracy: 0.8296 - val_loss: 0.4036 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f24071b7c8>"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.fit(x_train, y_train, validation_data=(x_test, y_test), batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = onehot_transformer.fit_transform(validation.drop('Survived', axis=1))\n",
    "y_val = validation.Survived.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "179/1 [==========================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 90us/sample - loss: 0.3981 - accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40359946685796344, 0.82122904]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl_model.evaluate(x_test, y_test, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle(grid_cv, test, dl=False):\n",
    "    if dl:\n",
    "        test_transformed = onehot_transformer.fit_transform(test)\n",
    "        test['Survived'] = grid_cv.predict(test_transformed).round(0).astype(int)\n",
    "    else:\n",
    "        test['Survived'] = grid_cv.predict(test)\n",
    "    print(test[['PassengerId', 'Survived']])\n",
    "    submission_df = test[['PassengerId', 'Survived']]\n",
    "    submission_df.to_csv('../output/titanic_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         1\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         1\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "kaggle(lgbm, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived\n",
      "0            892         0\n",
      "1            893         0\n",
      "2            894         0\n",
      "3            895         0\n",
      "4            896         0\n",
      "..           ...       ...\n",
      "413         1305         0\n",
      "414         1306         1\n",
      "415         1307         0\n",
      "416         1308         0\n",
      "417         1309         1\n",
      "\n",
      "[418 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "kaggle(dl_model, test, dl=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
